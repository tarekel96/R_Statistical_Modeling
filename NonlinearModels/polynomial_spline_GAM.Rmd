---
title: "Nonlinear models - polynomial, spline, GAM"
author: "Tarek El-Hajjaoui"
date: "2023-05-21"
output: html_document
---

## ISLR2 Chapter 7: Questions 9 & 10

```{r, message=FALSE}
library(caret) # trainControl( ), train( ) used for cross validation
library(splines) # bs() used to create matrix of basis functions for splines
library(leaps) # Forward stepwise selection
library(mgcv)
library(ggplot2)
library(ISLR2) # data(College)
```

### ISLR2 Chapter 7: Question 9

This question uses the variables dis (the weighted mean of distances to five Boston employment centers) and nox (nitrogen oxides concentration in parts per 10 million) from the Boston data. We will treat dis as the predictor and nox as the response.

Preprocessing Boston dataset

```{r}
file_path = '/Users/Tarek/Documents/UCI_MDS_Coding/Stats211P/R_Statistical_Modeling/ISLRv2_Datasets/Boston.csv'
df_boston <- read.csv(file_path, row.names = NULL, header = TRUE)
# keep only the 'dis' and 'nox' columns
df_boston <- df_boston[, c("dis", "nox")]
df_boston <- na.omit(df_boston) # drop na rows
# drop column X from the dataframe
df_boston$X <- NULL
```

```{r}
head(df_boston)
```

```{r}
str(df_boston) # ensure data types correct now
colSums(is.na(df_boston)) # count number of nulls in each column
nrow(df_boston)
```

```{r}
plot(df_boston$dis, df_boston$nox)
```

#### 9 a)

Use the poly() function to fit a cubic polynomial regression to predict nox using dis. Report the regression output, and plot the resulting data and polynomial fits.

```{r}
cubic_fit <- lm(nox ~ poly(dis, 3), data = df_boston)
```

Report the regression output
```{r}
# columns are a basis of orthogonal polynomials, 
# which means that each column is a linear combination
# of the variables dis, dis^2, dis^3 and dis^4
summary(cubic_fit)
```

Plot the resulting data and polynomial fits
```{r}
dislims <- range(df_boston$dis)

# grid of values for dis at which we want predictions
dis.grid <- seq(from = dislims[1], to = dislims[2])

nox_pred <- predict(cubic_fit, newdata = list(dis = dis.grid), se = TRUE)

plot(df_boston$dis, df_boston$nox, xlab = "dis", ylab = "nox", main = "Cubic Polynomial Regression")
lines(dis.grid, nox_pred$fit, col = "red", lwd = 2)
legend("topright", legend = "Cubic Fit", col = "red", lwd = 2)
```


#### 9 b)

Plot the polynomial fits for a range of different polynomial degrees (say, from 1 to 10), and report the associated residual sum of squares.

```{r}
# initialize an empty vector to store the RSS values
rss_values <- numeric(10)

par(mfrow = c(2, 5)) # 2 x 5 plotting matrix

# adjust bottom margin for the plots
par(oma = c(0, 0, 2, 0) + 0.1, mar = c(2, 1, 2, 1))

# iterate over different polynomial degrees
for (degree in 1:10) {
  # fit the polynomial regression model
  fit <- lm(nox ~ poly(dis, degree), data = df_boston)
  # predict the response variable
  nox_pred <- predict(fit, newdata = list(dis = dis.grid), se = TRUE)
  # calculate the residual sum of squares (RSS)
  rss <- sum((df_boston$nox - nox_pred$fit)^2)
  # store the RSS value
  rss_values[degree] <- rss
  # plot the polynomial fit
  plot(df_boston$dis, df_boston$nox, xlab = "dis", ylab = "nox", main = paste("Polynomial Deg:", degree))
  lines(dis.grid, nox_pred$fit, col = "red", lwd = 2)
  text(x = max(df_boston$dis), y = max(df_boston$nox), paste("RSS =", round(rss, 2)),
       pos = 2, offset = 0.5, adj = c(1, 1))
}

# associated RSS values
for (degree in 1:10) {
  cat("Degree", degree, ": RSS =", rss_values[degree], "\n")
}

par(mfrow = c(1,1))
```


#### 9 c)

Perform cross-validation or another approach to select the optimal degree for the polynomial, and explain your results.

```{r}
set.seed(0)

# range of polynomial degrees to consider
degree_range <- 1:10

# initialize an empty vector to store the cross-validated MSE values
mse_values <- numeric(length(degree_range))

# perform cross-validation for each degree
for (i in degree_range) {
  # polynomial features for the given degree
  poly_features <- poly(df_boston$dis, i)
  
  # combine the polynomial features with the response variable
  poly_data <- data.frame(nox = df_boston$nox, poly_features)
  
  # create a list of seeds for cross-validation
  cv_seeds <- vector("list", 11)
  for (j in 1:10) {
    cv_seeds[[j]] <- sample.int(1000, 1)  # use a different seed for each fold
  }
  cv_seeds[[11]] <- sample.int(1000, 1)  # Additional seed element
  
  # perform cross-validation using 10-fold cross-validation
  cv <- trainControl(method = "cv", number = 10, seeds = cv_seeds) # from caret library
  
  # fit the polynomial regression model and evaluate MSE using cross-validation
  fit <- train(nox ~ ., data = poly_data, method = "lm", trControl = cv) # from caret library
  
  # store the cross-validated MSE value
  mse_values[i] <- fit$results$RMSE
}

# find the optimal degree with the lowest cross-validated MSE
optimal_degree <- which.min(mse_values)

# plot the cross-validated MSE values
plot(degree_range, mse_values, type = "b", xlab = "Polynomial Degree", ylab = "Cross-Validated RMSE")

# Add a point to indicate the optimal degree
points(optimal_degree, mse_values[optimal_degree], col = "red", pch = 16)

# Add a text label for the optimal degree
legend_text <- paste("Optimal Degree:", optimal_degree, "\nCross-Validated RMSE:", mse_values[optimal_degree])
legend("topleft", legend = legend_text, col = "red", pch = 16)

# print optimal degree and the associated cross-validated MSE value
cat("Optimal Degree:", optimal_degree, "\n")
cat("Cross-Validated RMSE:", mse_values[optimal_degree], "\n")
```

Polynomial 10-Fold CV Results:

- 10-fold cross validation was performed on different polynomial degrees, ranging from 1 - 10, with the help of the caret library. The train method returns a dataframe of the training error rate for the 10-fold validation. For each ith degree, the root mean squared error (RMSE) is stored. In the graph above the RMSE for each ith degree is plotted. 4th degree has the lowest RMSE so a polynomial degree of 4 is chosen. It should be noted there are different factors that influence the results such as random seeding; however, overall the RMSE for all degrees are relatively close.


#### 9 d)

Use the bs() function to fit a regression spline to predict nox using dis. Report the output for the fit using four degrees of freedom. How did you choose the knots? Plot the resulting fit.

Report the output for the fit using four degrees of freedom
```{r}
# regression spline with four degrees of freedom
spline_fit <- lm(nox ~ bs(dis, df = 4), data = df_boston)
summary(spline_fit)
```

Plot the resulting fit
```{r}
spline_pred <- predict(spline_fit, newdata = list(dis = dis.grid), se = T)
plot(df_boston$dis, df_boston$nox, xlab = "dis", ylab = "nox", main = "Spline Regression (df=4)")
# uncomment below if want to see standard 95% confidence interval
# lines(dis.grid, spline_pred$fit + 2 * spline_pred$se, lty = "dashed", col = "red")
# lines(dis.grid, spline_pred$fit - 2 * spline_pred$se, lty = "dashed", col = "red")
lines(dis.grid, spline_pred$fit, col = "red", lwd = 2)
```

How the knots were chosen?

- The bs() function with df specified determines the placement of knots based on the data. The number of degrees of freedom (df) controls the number and placement of internal knots in the spline, which determines the flexibility of the spline fit.

#### 9 e)

Now fit a regression spline for a range of degrees of freedom, and plot the resulting fits and report the resulting RSS. Describe the results obtained.

```{r}
# define the range of degrees of freedom to consider
df_range <- 3:12

# initialize an empty vector to store the RSS values
rss_values <- numeric(length(df_range))

par(mfrow = c(2, 5)) # 2 x 5 plotting matrix

# adjust bottom margin for the plots
par(oma = c(0, 0, 2, 0) + 0.1, mar = c(2, 1, 2, 1))

# iterate over the range of degrees of freedom
for (i in df_range) {
  # fit regression spline with the current degrees of freedom
  spline_fit <- lm(nox ~ bs(dis, df = i), data = df_boston)
  
  # predict the response variable
  nox_pred <- predict(spline_fit, newdata = list(dis = dis.grid), se = T)
  
  # calculate the residual sum of squares (RSS)
  rss <- sum((df_boston$nox - nox_pred$fit)^2)
  
  # store the RSS value
  rss_values[i] <- rss
  
  # plot the data
  plot(df_boston$dis, df_boston$nox, xlab = "dis", ylab = "nox", main = paste("Spline Fit ( df = ", i, ")"))
  
  # plot the resulting fit
  lines(dis.grid, nox_pred$fit, col = "red", lwd = 2)
  
  text(x = max(df_boston$dis), y = max(df_boston$nox), paste("RSS  =", round(rss, 2)),
       pos = 2, offset = 0.5, adj = c(1, 1))
}

# print the resulting RSS values
for (i in df_range) {
  cat("Degrees of Freedom:", i, "RSS =", rss_values[i], "\n")
}

```

Spline Degrees of Freedom Results:

- The spline model with 8 degrees of freedom has the lowest residual sum of squares (RSS), which suggests its the optimal df value. In general, higher values of df allow for more flexibility and can result in a better fit to the data. However as the df becomes too high, the model starts to fit the noise and random variations in the training data, leading to overfitting. The model becomes too complex and loses its ability to generalize well to new data, which is why the df values higher than 8 have higher RSS values.

#### 9 f)

Perform cross-validation or another approach in order to select the best degrees of freedom for a regression spline on this data. Describe your results.

```{r}
set.seed(0)

# range of polynomial degrees to consider
degree_range <- 3:12
index <- 1

# initialize an empty vector to store the cross-validated MSE values
mse_values <- numeric(length(degree_range))

# perform cross-validation for each degree
for (i in degree_range) {
  # spline features for the given degree
  bs_features <- bs(df_boston$dis, df = i)
  
  # combine the spline features with the response variable
  spline_data <- data.frame(nox = df_boston$nox, bs_features)
  
  # create a list of seeds for cross-validation
  cv_seeds <- vector("list", 11)
  for (j in 1:10) {
    cv_seeds[[j]] <- sample.int(1000, 1)  # use a different seed for each fold
  }
  cv_seeds[[11]] <- sample.int(1000, 1)  # Additional seed element  
  
  # perform cross-validation using 10-fold cross-validation
  cv <- trainControl(method = "cv", number = 10, seeds = cv_seeds) # from caret library
  
  # fit the spline regression model and evaluate MSE using cross-validation
  fit <- train(nox ~ ., data = spline_data, method = "lm", trControl = cv) # from caret library
  
  # store the cross-validated MSE value
  mse_values[index] <- fit$results$RMSE
  
  # increment the index
  index <- index + 1
}

# find the optimal degree with the lowest cross-validated MSE
optimal_degree <- degree_range[which.min(mse_values)]

# plot the cross-validated MSE values
plot(degree_range, mse_values, type = "b", xlab = "Spline df", ylab = "Cross-Validated RMSE")

# point to indicate the optimal degree
points(optimal_degree, mse_values[which.min(mse_values)], col = "red", pch = 16)

# text label for the optimal degree
legend_text <- paste("Optimal Degree:", optimal_degree, "\nCross-Validated RMSE:", mse_values[which.min(mse_values)])
legend("topright", legend = legend_text, col = "red", pch = 16)
```

Spline Degrees of Freedom 10-Fold CV Results:

- The results above provide stronger evidence about choosing the optimal df because 10-fold cross validation was performed on different degrees of freedom, ranging from 3 - 12, with the help of the caret library. The train method returns a dataframe of the training error rate for the 10-fold validation. For each ith degree of freedom, the root mean squared error (RMSE) is stored. In the graph above the RMSE for each ith degree is plotted. 10 degrees of freedom has the lowest RMSE but, 6 degrees of freedom has a very comparable RSS value and perhaps would be a better model choice to minimize overfitting effects.

### ISLR2 Chapter 7: Question 10

Loading College dataset and preprocessing

```{r}
file_path = '/Users/Tarek/Documents/UCI_MDS_Coding/Stats211P/R_Statistical_Modeling/ISLRv2_Datasets/College.csv'
#df_college <- read.csv(file_path, row.names = NULL, header = TRUE)
df_college <- data(College)
df_college <- na.omit(df_college)
# drop column X from the dataframe
df_college$X <- NULL
```

```{r}
categorical_cols <- c('Private')
df_college[categorical_cols] <- lapply(df_college[categorical_cols], as.factor)
```

```{r}
str(df_college) # ensure data types correct now
colSums(is.na(df_college)) # count number of nulls in each column
nrow(df_college)
```

#### 10 a)

Split the data into a training set and a test set. Using out-of-state tuition as the response and the other variables as the predictors.

Split the data set into a training set and a test set.
```{r}
set.seed(0) # set random seed for reproducibility
# split the dataframe into train and test sets
train_indices <- createDataPartition(df_college$Outstate, p = 0.7, list = FALSE)
train_college <- df_college[train_indices, ]
train_y <- data.matrix(subset(train_college, select=c('Outstate')))
train_X <- data.matrix(train_college[,!names(train_college) %in% c("Outstate")])
dim(train_X);dim(train_y) # checking dims of split data
test_college <- df_college[-train_indices, ]
test_y <- data.matrix(subset(test_college, select=c('Outstate')))
test_X <- data.matrix(test_college[,!names(test_college) %in% c("Outstate")])
dim(test_X);dim(test_y) # checking dims of split data
```

Perform forward stepwise selection on the training set in order to identify a satisfactory model that uses just a subset of the predictors.
```{r}
set.seed(0)
forward_fit <- regsubsets(Outstate ~ ., nvmax = 18, data = train_college, method = "forward")

# find the best model based on BIC (Bayesian Information Criterion)
best_model <- which.min(summary(forward_fit)$bic)

cat("Best model using", best_model, "predictors.\n")

# get the predictors selected by the best model
selected_predictors <- names(coef(forward_fit, best_model))[-1]

cat("Selected Predictors:\n")
coef(forward_fit, best_model)
```

#### 10 b)

Fit a GAM on the training data, using out-of-state tuition as the response and the features selected in the previous step as the predictors. Plot the results, and explain your findings.

```{r}
set.seed(0)
# fit a GAM using the selected predictors
gam_fit <- gam(Outstate ~ Private + s(Apps) + s(Accept) + s(Top10perc) + s(F.Undergrad) + s(Room.Board) + s(Personal) + s(PhD) + s(S.F.Ratio) + s(Terminal) + s(perc.alumni) + s(Expend) + s(Grad.Rate),
               data = train_college)
plot(gam_fit, pages = 1, se = TRUE, col = "blue")
```

The solid lines in each of the graphs above represent the estimated effect of a predictor on the response (Outstate). It depicts the relationship between the predictor and the response after adjusting for the effects of all other variables in the model. The two dotted lines represent a 95% confidence interval.

Some example of interpretations:

- It can be observed that Expend and Grad.Rate each appear to have a very non-linear relationship with Outstate.
- Conversely per.alumni appears to have a non-linear relationship with Outstate but overall its pattern could arguably be generalized as a positive linear relationship with response. 
- Terminal has a slightly non-linear relationship with the response with a slope that seems to converge at higher levels of Terminal.

#### 10 c)

Evaluate the model obtained on the test set, and explain the results obtained.

```{r}
set.seed(0)
# Predict values for the test set
predicted_values <- predict(gam_fit, newdata = test_college)

# Calculate mean squared error (MSE)
mse <- mean((test_college$Outstate - predicted_values)^2)
cat("Test set Mean Squared Error:", mse, "\n")

# Calculate root mean squared error (RMSE)
rmse <- sqrt(mse)
cat("Test set Root Mean Squared Error:", rmse, "\n")

cat("Standard Deviation of Outstate from dataset:", sd(test_college$Outstate), "\n")
```

GAM Test set Results

- The Generalized Additive Model's test set MSE and RMSE is printed above. On average, the model's predictions are around 1,855.938 off from the actual out-of-state tuition. For comparison, the standard deviation of the test set's Outstate, 4,151.108, is printed. Since the RMSE is significantly smaller than the variance, it suggests that the model is capturing a significant proportion of the variance.

#### 10 d)

For which variables, if any, is there evidence of a non-linear relationship with the response?

```{r}
summary(gam_fit)
```

- In the summary output, the smoothing term p-values tell us which variables have evidence of a non-linear relationship. A p-value smaller than the significance level (0.05) suggests that there is evidence of a non-linear relationship between that predictor and the response variable. 
- Most of the smoothing terms have evidence for non-linear relationships. Room.Board and Expend have very strong evidence for having a non-linear relationship with the response which aligns with the graphs observations in part b. Some terms have weaker evidence supporting the claim it has a non-linear relationship with Outstate. For example perc.alumni and Grad.Rate have p-values less than 0.05, but are larger than the p-values of Room.Board and Expend.
- 5 of the terms do not have evidence for a non-linear relationship because their values are greater than 0.05. These terms are: Terminal, PhD, Personal, Top10perc, and Apps. 
