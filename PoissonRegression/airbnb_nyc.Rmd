---
title: "Airbnb NYC"
author: "Tarek El-Hajjaoui"
date: "2023-04-23"
output: html_document
---

```{r, echo=FALSE, results="hide", warning=FALSE, message=FALSE}
# library
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(kableExtra)
library(knitr)
```

### Q 4.11.3.1 Airbnb in NYC
Perform an EDA, build a model, and interpret model coefficients to describe variation in the number of reviews (a proxy for the number of rentals, which is not available) as a function of the variables provided. Donâ€™t forget to consider an offset, if needed.

```{r}
# Loading the dataset
file_path = './NYCairbnb.csv'
df = read.csv(file_path, header = TRUE)
```

```{r}
# View dataframe summary
str(df)
```

####  Q 4.11.3.1 Airbnb in NYC - Explanatory Data Analysis (EDA)

Preprocessing - transforming data types
```{r}
# Transforming categorical columns to factor data type.
categorical_cols <- c('room_type', 'bathrooms', 'bedrooms', 'review_scores_cleanliness', 'review_scores_location', 'review_scores_value', 'instant_bookable')
df[categorical_cols] <- lapply(df[categorical_cols], as.factor)

# Transforming date columns
date_cols <- c('last_scraped', 'host_since')
df[date_cols] <- lapply(df[date_cols], as.Date)
```

**Checking if the data justifies a Poisson regression model.**

Plotting the $Y$, number of reviews.
```{r}
ggplot(df, aes(number_of_reviews)) +
  geom_histogram(binwidth = .25, color = "black", fill = "white") +
  xlim(0, 100) +
  xlab("Number of reviews") +
  ylab("Count of the number of reviews")

max(df[['number_of_reviews']])
```

**Note:** X-axis has been condensed for visual reasons, however, there are some (not many) AirBnB observations with number of reviews ranging from 100-421.

- Number of reviews appears to follow a Poisson distribution given by the right-skewed histogram above. As the number of reviews increases, the count of the number of reviews decreases.

Checking for the assumption of $\mu = \sigma^2$ (mean = variance).
```{r, echo=FALSE, message = FALSE}

# Mean = Variance [group by review_scores_cleanliness]
table1<- df  %>% group_by(review_scores_cleanliness)  %>% 
  summarise(mnNum= mean(number_of_reviews),varNum=var(number_of_reviews),n=n())
k1 <- kable(table1, booktabs=T, 
      caption="Compare mean and variance of the number of reviews for the review score cleaniness groups.",col.names = c("review_scores_cleanliness", "Mean", "Variance", "n")) %>% kable_styling(full_width = F)

# Mean = Variance [group by review_scores_location]
table2<- df  %>% group_by(review_scores_location)  %>% 
  summarise(mnNum= mean(number_of_reviews),varNum=var(number_of_reviews),n=n())
k2 <- kable(table2, booktabs=T, 
      caption="Compare mean and variance of the number of reviews for the review score location groups.",col.names = c("review_scores_location", "Mean", "Variance", "n"))%>% kable_styling(full_width = F)

# Mean = Variance [group by review_scores_value]
table3<- df  %>% group_by(review_scores_value)  %>% 
  summarise(mnNum= mean(number_of_reviews),varNum=var(number_of_reviews),n=n())
k3 <- kable(table3, booktabs=T, 
      caption="Compare mean and variance of the number of reviews for the review score value groups.",col.names = c("review_scores_value", "Mean", "Variance", "n")) %>% kable_styling(full_width = F)

# display mean and variance tables of features
k1 
k2
k3
```
There is some evidence of a violation of the mean=variance assumption. It appears that the variance is smaller than the mean for lower number of reviews, while the variance is greater than the mean for higher number of reviews. 

The Poisson regression model implies that log($\lambda_i$) is a linear function of feature variables; i.e., $log(\lambda_i)=\beta_0+\beta_i\textrm{feature}_i$. Therefore, to check the linearity assumption for Poisson regression, we would like to plot log($\lambda_i$) by $\beta_i$.

```{r}
# Remove rows where x is null
df_no_nulls <- df[complete.cases(df), ]

sumStats <- df_no_nulls %>% group_by(review_scores_cleanliness) %>%
  summarise(mn_reviews = mean(number_of_reviews),
            logmn_reviews = log(mn_reviews), n=n())

sumStats2 <- df_no_nulls %>% group_by(review_scores_location) %>%
  summarise(mn_reviews = mean(number_of_reviews),
            logmn_reviews = log(mn_reviews), n=n())

sumStats3 <- df_no_nulls %>% group_by(review_scores_value) %>%
  summarise(mn_reviews = mean(number_of_reviews),
            logmn_reviews = log(mn_reviews), n=n())

plot1 <- ggplot(sumStats, aes(x=review_scores_cleanliness, y=logmn_reviews)) +
  geom_point()+
  geom_smooth()+
  xlab("review_scores_cleanliness") +
  ylab("log(n_reviews)")

plot2 <- ggplot(sumStats2, aes(x=review_scores_location, y=logmn_reviews)) +
  geom_point()+
  geom_smooth()+
  xlab("review_scores_location") +
  ylab("log(n_reviews)")

plot3 <- ggplot(sumStats3, aes(x=review_scores_value, y=logmn_reviews)) +
  geom_point()+
  geom_smooth()+
  xlab("review_scores_value") +
  ylab("log(n_reviews)")

# Arrange the plots in a row using grid.arrange()
grid.arrange(plot1, plot2, plot3, ncol = 2)
```

The graphs above suggest that the number of reviews follow a Poisson distribution. The $log(\lambda)$ (where $\lambda$ = mean number of reviews per group of $\beta_i$) has a linear pattern which suggests that Poisson is appropriate.

#### Q 4.11.3.1 Airbnb in NYC - Offset

In general, when using a Poisson regression model, the variable to be offset should be a measure of exposure or effort. For this dataset, the variable to be offset would be a measure of the time that each rental unit is available for rent which is *days*.

Plotting $Y$, number of reviews against log(days).
```{r}
p1 <- ggplot(df, aes(x = days, y = number_of_reviews)) +
  geom_point() +
  xlab("days") +
  ylab("number of reviews")

p2 <- ggplot(df, aes(x=log(days), y=number_of_reviews)) +
  geom_point() +
  xlab("log(days)") +
  ylab("rate of number of reviews")

# Arrange the plots in a row using grid.arrange()
grid.arrange(p1, p2, ncol = 2)

# calculate correlation
cor(df$days, df$number_of_reviews)
```

The rate of increase in the number of reviews is exponential which suggets that log(days) may be needed to offset for the non-constant rate of number of reviews. The offset variable will be tested further in model building. 

#### Q 4.11.3.1 Airbnb in NYC - Model Building

Creating 2 models with the same predictors, but the first reduced model does not contain an offset variable of log(days).
```{r}
no_offset_model <- glm(number_of_reviews ~ review_scores_cleanliness + review_scores_location + review_scores_value,
                     data = df, family = poisson)
full_poisson_model <- glm(number_of_reviews ~ review_scores_cleanliness + review_scores_location + review_scores_value + offset(log(days)),
                     data = df, family = poisson)
```

```{r}

# data frame to summarize model comparisons
model_stats_df <- data.frame(
  Model = c("No Offset", "Offset"),
  Residual_Deviance = c(deviance(no_offset_model),deviance(full_poisson_model)),
  AIC = c(AIC(no_offset_model), AIC(full_poisson_model)),
  BIC = c(BIC(no_offset_model), BIC(full_poisson_model))
)

model_stats_df

```

The model without the offset has lower residual deviances, AIC, and BIC which suggests the model with the offset is not a better fit for the data than the model without the offset. This is because the residual deviance measures the lack of fit of the model to the data, and AIC/BIC provides a measure of the quality of the model in terms of goodness of fit and parsimony. A higher residual deviance and AIC both suggest a worse model fit, thus the model without offset will be used.

#### Q 4.11.3.1 Airbnb in NYC - Coefficient Interpretation
```{r}
# Obtaining coefficient estimates
coef_estimates <- coef(no_offset_model)

# Exponentiating coefficients to be able to interpret coefficients
# Because exponentiating the coefficient allows us 
# to obtain the multiplicative factor by which the mean count changes
exp_coef <- exp(coef_estimates)
round(exp_coef, 4)
```

Because we are working with categorical features (review_scores_cleanliness, review_scores_location, review_scores_values) each of their factors are considered a covariate in the Poisson models. Each coefficient was exponentiated to be able to interpret coefficients, which allows us to obtain the multiplicative factor by which the mean count changes. Some of the interpretations are translated below. 

For a **1 unit increase in the predictor variable**:

- *review_scores_cleanliness4*: the expected the response variable ($\lambda$ = estimated mean number of reviews) would decrease by a factor of approximately 0.7636 holding all other variables constant.
- *review_scores_location8*: the expected the response variable ($\lambda$ = estimated mean number of reviews) would increase by a factor of approximately 1.4741 holding all other variables constant.
- *review_scores_value9*: the expected the response variable ($\lambda$ = estimated mean number of reviews) would decrease by a factor of approximately 6.7350 holding all other variables constant.

<!-- ```{r} -->
<!-- # Create a matrix for plots -->
<!-- # par(mfrow = c(1, 1)) -->

<!-- # Set up the plotting device with a larger width -->
<!-- #options(repr.plot.width = 8, repr.plot.height = 4) -->
<!-- # Set the margins for each individual plot -->
<!-- par(mar = c(4, 4, 2, 1),mfrow = c(2, 2)) -->

<!-- plot(df[['review_scores_cleanliness']], df$number_of_reviews, xlab='review_scores_cleanliness', ylab="n_reviews", type = "h") -->
<!-- plot(df[['review_scores_location']], df$number_of_reviews, xlab='review_scores_location', ylab="number_of_reviews", type = "h") -->
<!-- plot(df[['review_scores_value']], df$number_of_reviews, xlab='review_scores_value', ylab="number_of_reviews", type = "h") -->
<!-- ``` -->

<!-- To test out if the full model (model with the offset variable) is needed, the Likelihood Ratio Test (LRT) will be performed. Likelihood refers to the probability of observing the data given the model and the estimated parameters. The ANOVA (Analysis of variance) will be used to conduct the LRT. -->
<!-- ```{r} -->
<!-- # Perform the likelihood ratio test using anova() -->
<!-- anova(no_offset_model, full_poisson_model, test = "LRT") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Calculate test statistic and p-value -->
<!-- test_stat <- 2 * (logLik(full_poisson_model) - logLik(no_offset_model)) -->
<!-- test_stat -->
<!-- #p_value <- pchisq(test_stat, df = 1, lower.tail = FALSE) -->
<!-- #p-value -->
<!-- ``` -->

<!-- The test statistic from the Log Likelihood test is too large to calculate a p-value from the Chi-square distribution and so a different method, the AIC metric, will be used to compare the models. -->

<!-- ```{r} -->
<!-- # Compute AIC and BIC -->
<!-- results <- data.frame( -->
<!--   model = c("no_offset_model", "full_poisson_model"), -->
<!--   df = AIC(no_offset_model, full_poisson_model)$df, -->
<!--   AIC = AIC(no_offset_model, full_poisson_model)$AIC, -->
<!--   BIC = BIC(no_offset_model, full_poisson_model)$BIC -->
<!-- ) -->

<!-- results -->
<!-- ``` -->

